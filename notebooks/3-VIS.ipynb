{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipyplot\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipyplot'"
     ]
    }
   ],
   "source": [
    "import sys,json\n",
    "import pandas as pd\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "while 'configs' not in os.listdir('.'):\n",
    "    os.chdir('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import BCELoss, CrossEntropyLoss\n",
    "\n",
    "# Set the directory path\n",
    "RESULTS_ROOT = './results/'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "img_transform = transforms.Compose([ transforms.ToTensor()])\n",
    "# transform for mask\n",
    "msk_transform = transforms.Compose([transforms.ToTensor()])\n",
    "msk_transform = torch.tensor\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from adaptive_mis.common import load_config,loader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ipyplot,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7889374c37354bf292f704c2cda4bb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('isic',), value='isic'), Output()), _dom_classe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Torch device: {device}\")\n",
    "def get_model(cfg,model_dir,fold):\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    best_model = best_model.to(device)\n",
    "\n",
    "    fn = \"best_model_state_dict.pt\"\n",
    "    model_path = f\"{model_dir}/{fold}/{fn}\"\n",
    "\n",
    "    best_model.load_state_dict(torch.load(model_path))\n",
    "    result_file_path = f\"{model_dir}/{fold}/result.json\"\n",
    "    with open(result_file_path, 'r') as f:\n",
    "        results = json.loads(''.join(f.readlines()))\n",
    "    best = results['best_result']\n",
    "    print(f\"{model_dir.split('/')[-1]} Loaded best model weights... best loss: tr:{best['tr_loss']:0.5f} val:{best['vl_loss']:0.5f}\")\n",
    "    return best_model\n",
    "\n",
    "@widgets.interact\n",
    "def datasets(dataset=sorted([f for f in os.listdir(RESULTS_ROOT) if not f.startswith('.')])):\n",
    "        # ipyplot.plot_images(debug_imgs, max_images=4, img_width=150)\n",
    "        ROOT=f'{RESULTS_ROOT}/{dataset}'\n",
    "        valid_files=[f for f in os.listdir(ROOT) if os.path.isfile(os.path.join(ROOT, f, 'full_test.csv'))]\n",
    "        runns = sorted(valid_files, key=lambda x: os.path.getmtime(os.path.join(f'{RESULTS_ROOT}/{dataset}', x)), reverse=True)\n",
    "\n",
    "        @widgets.interact_manual\n",
    "        def compare(dirs=widgets.SelectMultiple(options=runns, description='Runns',           layout=widgets.Layout(width='100%', height='180px')),titles=\"comma seperated\"):\n",
    "            allmetrics={}\n",
    "            models={}\n",
    "            display_names={} \n",
    "            \n",
    "            for i,d in enumerate(dirs):\n",
    "                # try:\n",
    "                    cfg=load_config(f'{ROOT}/{d}/config.yaml')\n",
    "                    date=d.split('_')[-1]\n",
    "                    if len(titles.split(','))==len(dirs):\n",
    "                        display_names[d]= titles.split(',')[i]\n",
    "                    else:\n",
    "                        display_names[d]=d.replace(dataset+\"_\",'').replace(\"_\"+date,'')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    metrics=pd.read_csv(f'{ROOT}/{d}/full_test.csv',header=0,index_col=0)\n",
    "                    metrics['eval']=cfg['evaluation']['title']\n",
    "                    metrics['model']=display_names[d]\n",
    "                    # metrics['date']=date\n",
    "                    # display(metrics)\n",
    "                    allmetrics[d] = metrics\n",
    "                    \n",
    "                # except Exception as e:\n",
    "                #     print(f\"skip {d} due to error-->{e}\")\n",
    "            \n",
    "            df=pd.concat(allmetrics,axis=0).reset_index(0).rename(columns={'level_0':'file'}).sort_values('JaccardIndex', ascending=False)\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            display(df.loc['avg'].round(5))\n",
    "            df=df.loc['avg'].groupby(['model']).agg({'Accuracy':['mean','std'],'Dice':['mean','std'],'JaccardIndex':['mean','std','count']}).sort_values(('JaccardIndex','mean'), ascending=False)\n",
    "            df=df.round(4)\n",
    "            display(df)\n",
    "            df=df.astype(str)\n",
    "            df_new=pd.DataFrame()\n",
    "            df_new['Accuracy']=df[('Accuracy','mean')] +\"±\"+ df[('Accuracy','std')]\n",
    "            df_new['Dice']=df[('Dice','mean')] +\"±\"+ df[('Dice','std')]\n",
    "            df_new['IoU']=df[('JaccardIndex','mean')] +\"±\"+ df[('JaccardIndex','std')]\n",
    "            display(df_new)\n",
    "            print(df_new.to_latex()) #.replace('±','\\pm'))\n",
    "            \n",
    "            # dataset=loader(cfg,'dataset')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @widgets.interact\n",
    "            # def select_case(image_number=widgets.IntSlider(0,0,len(dataset))):\n",
    "            #     item=dataset[image_number]\n",
    "            #     img,msk=item['image'].cpu().numpy().astype('float32'),item['mask'].cpu().numpy().astype('float32')\n",
    "            #     imgv=img=np.transpose(img,(1, 2, 0))\n",
    "            #     if img.shape[-1]==4:\n",
    "            #         imgv=img[...,:-1]\n",
    "\n",
    "            #     nonzero = np.where(imgv != 0)\n",
    "            #     roi=np.zeros((imgv.ndim,2))\n",
    "            #     for i in range(len(nonzero)):\n",
    "            #         if len(nonzero[i]) > 0:\n",
    "            #             roi[i][0] = max(0, nonzero[i].min())\n",
    "            #             roi[i][1] = min( imgv.shape[i], nonzero[i].max() + 1)\n",
    "\n",
    "            #     # print(img.shape)\n",
    "            #     # debug_imgs=[img]\n",
    "            #     added=(img[...,-1]>0)*dataset.startswith('segpc')*.1\n",
    "            #     # plt.imshow(imgs[image_number][:,:,:-1])\n",
    "            #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            #     fig, axs = plt.subplots(1, len(models)+2, sharex=True, sharey=True)\n",
    "            #     fig.set_size_inches(1000/80, fig.get_figheight())\n",
    "\n",
    "            #     axs[0].imshow(imgv)\n",
    "            #     # axs[0].set_xlim(roi[1][0], roi[1][1])\n",
    "            #     # axs[0].set_ylim(roi[0][0], roi[0][1])\n",
    "            #     axs[1].set_title('GT')\n",
    "            #     plt.axis('off')\n",
    "            #     for i in range(len(axs)):\n",
    "            #         axs[i].axis('off')\n",
    "            #     torch_msk=torch.stack([torch.tensor(msk).to(device)])\n",
    "            #     msk=np.argmax(msk,0)\n",
    "            #     axs[1].imshow(msk+added, cmap='gist_stern')\n",
    "            #     torch_img=torch.stack([transforms.ToTensor()(img).to(device)])\n",
    "                \n",
    "                \n",
    "                \n",
    "            #     msks_ = torch.argmax(torch_msk, 1, keepdim=False)\n",
    "            #     tmpres={}\n",
    "            #     for i,d in enumerate(models):\n",
    "            #         preds=models[d](torch_img)\n",
    "            #         preds_ = torch.argmax(preds, 1, keepdim=False).float()\n",
    "            #         pred=preds.detach().cpu().numpy()[0][1,...]\n",
    "            #         pred=pred>0.5\n",
    "            #         # print(pred.shape,msk.shape,pred.max(),msk.max(),pred.min(),msk.min())\n",
    "                    \n",
    "            #         # print(pred.max())\n",
    "            #         axs[i+2].imshow(pred+added, cmap='gist_stern')\n",
    "            #         axs[i+2].set_title(display_names[d])\n",
    "            #         metrics=get_metrics().to(device)\n",
    "            #         metrics.update(preds_, msks_)\n",
    "                    \n",
    "            #         # cm = confusion_matrix(msk.reshape(-1), pred.reshape(-1),)\n",
    "            #         # print(display_names[d])\n",
    "                    \n",
    "            #         tmpres[d]={k: float(v.cpu().numpy()) for k, v in metrics.compute().items()}\n",
    "                    \n",
    "            #         # with open(f'{directory}/{d}/result.json', 'r') as f:\n",
    "            #         #     results = json.load(f)\n",
    "            #         # allmetrics[display_name] = {k.split('/')[-1]:v for k,v in results['best_result']['te_metrics'].items()}\n",
    "            #         # del models[d]\n",
    "            #     # print(tmpres)\n",
    "            #     plt.tight_layout()\n",
    "            #     plt.show()  \n",
    "            #     display(\"Only Current Image\")\n",
    "            #     display(pd.DataFrame(tmpres).T.round(4).sort_values('JaccardIndex', ascending=False))\n",
    "\n",
    "                \n",
    "\n",
    "#isic2018 --> 61"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
