{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed8431b69cd4a28be731360487a1d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='dataset', options=('select dataset', 'isic.yaml', 'segpc.yaml'), value='select dataset')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................continuing...\n",
      "selected dataset=./configs/datasets/segpc.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets\n",
    "import adaptive_mis as mis\n",
    "import adaptive_mis.common.jupyter_utils as ju\n",
    "from adaptive_mis.common import load_config\n",
    "from adaptive_mis.common import printc\n",
    "if 'datasets' not in os.listdir('.'):\n",
    "    os.chdir('../')\n",
    "\n",
    "CONFIG_ROOT=\"./configs\"\n",
    "DATASETS_ROOT=f\"{CONFIG_ROOT}/datasets\"\n",
    "MODELS_ROOT=f\"{CONFIG_ROOT}/models\"\n",
    "ADAPTIVE_LAYERS_ROOT=f\"{MODELS_ROOT}/adaptive\"\n",
    "EVAL_ROOT=f'{CONFIG_ROOT}/evaluation'\n",
    "\n",
    "all_datasets=sorted(os.listdir(DATASETS_ROOT))\n",
    "all_datasets.insert(0,'select dataset')\n",
    "dataset_dd=ipywidgets.Dropdown(options=all_datasets,description=\"dataset\")\n",
    "display(dataset_dd)\n",
    "ju.wait_for_user(dataset_dd)\n",
    "dataset_cfg=f'{DATASETS_ROOT}/{dataset_dd.value}'\n",
    "print(f'selected dataset={dataset_cfg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3d061596f94a5d872cd1284dbf2887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Adaptive Layer (optional)', options=('No Adaptive Layer', 'acda.yaml', 'adaptive.yaml'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95705c17f8574b7a88671fea9d5c3476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Main Model', options=('select model', 'acda_uctransnet.yaml', 'adapt_uctransnet.yaml', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................continuing...\n",
      "Selected Adaptive Layer None\n",
      "Selected Main Model ./configs/models/unet_3.yaml\n"
     ]
    }
   ],
   "source": [
    "all_adaptive_layers=sorted(os.listdir(ADAPTIVE_LAYERS_ROOT))\n",
    "all_adaptive_layers.insert(0,\"No Adaptive Layer\")\n",
    "adaptive_dd=ipywidgets.Dropdown(options=all_adaptive_layers,description=\"Adaptive Layer (optional)\")\n",
    "display(adaptive_dd)\n",
    "all_models=sorted([f for f in os.listdir(MODELS_ROOT) if f.endswith(\".yaml\")])\n",
    "all_models.insert(0,'select model')\n",
    "model_dd=ipywidgets.Dropdown(options=all_models,description=\"Main Model\")\n",
    "display(model_dd)\n",
    "ju.wait_for_user(model_dd)\n",
    "adaptive_layer_cfg=f'{ADAPTIVE_LAYERS_ROOT}/{adaptive_dd.value}' if \"No Adaptive Layer\" not in  adaptive_dd.value else None\n",
    "main_model_cfg=f'{MODELS_ROOT}/{model_dd.value}'\n",
    "\n",
    "print(\"Selected Adaptive Layer\", adaptive_layer_cfg)\n",
    "print(\"Selected Main Model\", main_model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb087a5866e849c4b23dfe1295bbc8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Evaluation', options=('select evaluation', 'demo.yaml', 'kfold.yaml', 'split.yaml'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................continuing...\n",
      "Selected Evaluation ./configs/evaluation/split.yaml\n"
     ]
    }
   ],
   "source": [
    "all_evaluations=sorted([f for f in os.listdir(EVAL_ROOT) if f.endswith(\".yaml\")])\n",
    "all_evaluations.insert(0,'select evaluation')\n",
    "eval_dd=ipywidgets.Dropdown(options=all_evaluations,description=\"Evaluation\")\n",
    "display(eval_dd)\n",
    "ju.wait_for_user(eval_dd)\n",
    "eval_cfg=f'{EVAL_ROOT}/{eval_dd.value}'\n",
    "print(\"Selected Evaluation\", eval_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset: !include ./configs/datasets/segpc.yaml\n",
      "evaluation: !include ./configs/evaluation/split.yaml\n",
      "run:\n",
      "    comet: False\n",
      "    save_dir: ./results/segpc/unet_3-2023-09-22T22-00-24\n",
      "\n",
      "model: !include ./configs/models/unet_3.yaml\n",
      "\n",
      "\n",
      "{\n",
      "  \"data_loader\": {\n",
      "    \"train\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"validation\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"test\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 4,\n",
      "      \"pin_memory\": false\n",
      "    }\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"optimizer\": {\n",
      "      \"name\": \"Adam\",\n",
      "      \"params\": {\n",
      "        \"lr\": 0.0001\n",
      "      }\n",
      "    },\n",
      "    \"criterion\": {\n",
      "      \"name\": \"DiceLoss\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "      \"factor\": 0.5,\n",
      "      \"patience\": 10\n",
      "    },\n",
      "    \"epochs\": 100\n",
      "  },\n",
      "  \"dataset\": {\n",
      "    \"title\": \"SegPC2021\",\n",
      "    \"class\": \"adaptive_mis.dataset.SegPC2021Dataset\",\n",
      "    \"params\": {\n",
      "      \"datadir\": \"datasets/SegPC2021\",\n",
      "      \"image_size\": 224,\n",
      "      \"crop_nucleus\": true,\n",
      "      \"crop_scale\": 2.5\n",
      "    }\n",
      "  },\n",
      "  \"evaluation\": {\n",
      "    \"class\": \"adaptive_mis.evaluation.Split\",\n",
      "    \"title\": \"Split\",\n",
      "    \"params\": {\n",
      "      \"seed\": 1,\n",
      "      \"val_size\": 0.2,\n",
      "      \"test_size\": 0.3\n",
      "    }\n",
      "  },\n",
      "  \"run\": {\n",
      "    \"comet\": false,\n",
      "    \"save_dir\": \"./results/segpc/unet_3-2023-09-22T22-00-24\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"class\": \"adaptive_mis.models.unet.UNet\",\n",
      "    \"load_weights\": false,\n",
      "    \"title\": \"UNet\",\n",
      "    \"params\": {\n",
      "      \"with_bn\": false,\n",
      "      \"first_kernel_size\": 3\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "def basename(path):\n",
    "    return os.path.basename(path).split('.')[0]\n",
    "\n",
    "\n",
    "if adaptive_layer_cfg:\n",
    "    model_cfg=f\"\"\"\n",
    "model: \n",
    "    class: \"adaptive_mis.models.adaptive.AdaptiveModel\"\n",
    "    title: \"AdaptCustom\"\n",
    "    load_weights: false\n",
    "    params:\n",
    "        adaptive_layer: !include {adaptive_layer_cfg}\n",
    "        main_model: !include {main_model_cfg}\n",
    "\"\"\"\n",
    "    model_title=f\"Adapt-{basename(adaptive_layer_cfg)}-{basename(main_model_cfg)}\"\n",
    "else:\n",
    "    model_cfg=f\"\"\"\n",
    "model: !include {main_model_cfg}\n",
    "\"\"\"\n",
    "    model_title=basename(main_model_cfg)\n",
    "    \n",
    "date = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "log = f'{basename(dataset_cfg)}/{model_title}-{date}'\n",
    "config=f\"\"\"\n",
    "dataset: !include {dataset_cfg}\n",
    "evaluation: !include {eval_cfg}\n",
    "run:\n",
    "    comet: False\n",
    "    save_dir: ./results/{log}\n",
    "{model_cfg}\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "print(config)\n",
    "\n",
    "\n",
    "cfg=load_config(f\"!include {CONFIG_ROOT}/common.yaml\")\n",
    "cfg.update(load_config(config))\n",
    "import json\n",
    "print(json.dumps(cfg, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cpu\n",
      "{\n",
      "  \"data_loader\": {\n",
      "    \"train\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"validation\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"test\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 4,\n",
      "      \"pin_memory\": false\n",
      "    }\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"optimizer\": {\n",
      "      \"name\": \"Adam\",\n",
      "      \"params\": {\n",
      "        \"lr\": 0.0001\n",
      "      }\n",
      "    },\n",
      "    \"criterion\": {\n",
      "      \"name\": \"DiceLoss\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "      \"factor\": 0.5,\n",
      "      \"patience\": 10\n",
      "    },\n",
      "    \"epochs\": 100\n",
      "  },\n",
      "  \"dataset\": {\n",
      "    \"title\": \"SegPC2021\",\n",
      "    \"class\": \"adaptive_mis.dataset.SegPC2021Dataset\",\n",
      "    \"params\": {\n",
      "      \"datadir\": \"datasets/SegPC2021\",\n",
      "      \"image_size\": 224,\n",
      "      \"crop_nucleus\": true,\n",
      "      \"crop_scale\": 2.5\n",
      "    }\n",
      "  },\n",
      "  \"evaluation\": {\n",
      "    \"class\": \"adaptive_mis.evaluation.Split\",\n",
      "    \"title\": \"Split\",\n",
      "    \"params\": {\n",
      "      \"seed\": 1,\n",
      "      \"val_size\": 0.2,\n",
      "      \"test_size\": 0.3\n",
      "    }\n",
      "  },\n",
      "  \"run\": {\n",
      "    \"comet\": false,\n",
      "    \"save_dir\": \"./results/segpc/unet_3-2023-09-22T22-00-24\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"class\": \"adaptive_mis.models.unet.UNet\",\n",
      "    \"load_weights\": false,\n",
      "    \"title\": \"UNet\",\n",
      "    \"params\": {\n",
      "      \"with_bn\": false,\n",
      "      \"first_kernel_size\": 3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- \n",
      "\n",
      "~~~~~~~~~~~~~~~ Fold 0/0 ~~~~~~~~~~~~~~~~~\n",
      "Length of trainig_dataset:\t1474\n",
      "Length of validation_dataset:\t369\n",
      "Length of test_dataset:\t\t790\n",
      "~~~~~~~~~~~~~~~ Fold 0/0 ~~~~~~~~~~~~~~~~~\n",
      "Number of parameters: 1947202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train) ep:000, batch:0093 -> curr_ml:0.02222, mbatch_l:0.12500: 100%|██████████| 93/93 [27:44<00:00, 17.90s/it, trl=0.02222 vll=0.01626 best_vll=0.01626]\n",
      "Train) ep:001, batch:0093 -> curr_ml:0.01577, mbatch_l:0.12500: 100%|██████████| 93/93 [19:53<00:00, 12.84s/it, trl=0.01577 vll=0.01626 best_vll=0.01626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\D\\Projects\\adaptive_mis\\notebooks\\2-Runner.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m adaptive_mis\u001b[39m.\u001b[39mreload()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39madaptive_mis\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mexecute(cfg)\n",
      "File \u001b[1;32mc:\\D\\Projects\\adaptive_mis\\adaptive_mis\\pipeline.py:197\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m# optimizer=loader(config,\"optimzier\")\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mwith\u001b[39;00m experiment\u001b[39m.\u001b[39mtrain():\n\u001b[1;32m--> 197\u001b[0m     best_model, model, res \u001b[39m=\u001b[39m train(\n\u001b[0;32m    198\u001b[0m         model,\n\u001b[0;32m    199\u001b[0m         tr_dataloader,\n\u001b[0;32m    200\u001b[0m         vl_dataloader,\n\u001b[0;32m    201\u001b[0m         config,\n\u001b[0;32m    202\u001b[0m         optimizer,\n\u001b[0;32m    203\u001b[0m         scheduler,\n\u001b[0;32m    204\u001b[0m         save_dir\u001b[39m=\u001b[39;49msave_dir,\n\u001b[0;32m    205\u001b[0m         save_file_id\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    206\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[0;32m    207\u001b[0m         fold\u001b[39m=\u001b[39;49mfold\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    209\u001b[0m     log_model(experiment, best_model, model_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel_f\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m experiment\u001b[39m.\u001b[39mvalidate():\n",
      "File \u001b[1;32mc:\\D\\Projects\\adaptive_mis\\adaptive_mis\\pipeline.py:380\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, tr_dataloader, vl_dataloader, config, optimizer, scheduler, num_classes, fold, save_dir, save_file_id)\u001b[0m\n\u001b[0;32m    378\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    379\u001b[0m loss, preds_, msks_ \u001b[39m=\u001b[39m process_batch(batch_data, model, device, num_classes, config, criterion)\n\u001b[1;32m--> 380\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    381\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    382\u001b[0m tr_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\comet_ml\\monkey_patching.py:324\u001b[0m, in \u001b[0;36mEntrypoint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m exception_raised \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     return_value \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    325\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n\u001b[0;32m    326\u001b[0m     exception_raised \u001b[39m=\u001b[39m exception\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import adaptive_mis\n",
    "adaptive_mis.reload()\n",
    "from adaptive_mis import pipeline\n",
    "\n",
    "pipeline.execute(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
