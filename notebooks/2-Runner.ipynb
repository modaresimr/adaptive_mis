{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575bbcd1fbc64a34a6db69cc639ff19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='dataset', options=('select dataset', 'isic.yaml', 'segpc.yaml'), value='select dataset')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................continuing...\n",
      "selected dataset=./configs/datasets/segpc.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets\n",
    "import adaptive_mis as mis\n",
    "import adaptive_mis.common.jupyter_utils as ju\n",
    "from adaptive_mis.common import load_config\n",
    "from adaptive_mis.common import printc\n",
    "if 'datasets' not in os.listdir('.'):\n",
    "    os.chdir('../')\n",
    "\n",
    "CONFIG_ROOT=\"./configs\"\n",
    "DATASETS_ROOT=f\"{CONFIG_ROOT}/datasets\"\n",
    "MODELS_ROOT=f\"{CONFIG_ROOT}/models\"\n",
    "ADAPTIVE_LAYERS_ROOT=f\"{MODELS_ROOT}/adaptive\"\n",
    "EVAL_ROOT=f'{CONFIG_ROOT}/evaluation'\n",
    "\n",
    "all_datasets=sorted(os.listdir(DATASETS_ROOT))\n",
    "all_datasets.insert(0,'select dataset')\n",
    "dataset_dd=ipywidgets.Dropdown(options=all_datasets,description=\"dataset\")\n",
    "display(dataset_dd)\n",
    "ju.wait_for_user(dataset_dd)\n",
    "dataset_cfg=f'{DATASETS_ROOT}/{dataset_dd.value}'\n",
    "print(f'selected dataset={dataset_cfg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab8a14a0b714271941bf6f37ec97e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Adaptive Layer (optional)', options=('No Adaptive Layer', 'acda.yaml', 'adaptive.yaml'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3485da9a66e34152b2e6ab1f5054ad7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Main Model', options=('select model', 'acda_uctransnet.yaml', 'adapt_uctransnet.yaml', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "...............................continuing...\n",
      "Selected Adaptive Layer None\n",
      "Selected Main Model ./configs/models/unet_3.yaml\n"
     ]
    }
   ],
   "source": [
    "all_adaptive_layers=sorted(os.listdir(ADAPTIVE_LAYERS_ROOT))\n",
    "all_adaptive_layers.insert(0,\"No Adaptive Layer\")\n",
    "adaptive_dd=ipywidgets.Dropdown(options=all_adaptive_layers,description=\"Adaptive Layer (optional)\")\n",
    "display(adaptive_dd)\n",
    "all_models=sorted([f for f in os.listdir(MODELS_ROOT) if f.endswith(\".yaml\")])\n",
    "all_models.insert(0,'select model')\n",
    "model_dd=ipywidgets.Dropdown(options=all_models,description=\"Main Model\")\n",
    "display(model_dd)\n",
    "ju.wait_for_user(model_dd)\n",
    "adaptive_layer_cfg=f'{ADAPTIVE_LAYERS_ROOT}/{adaptive_dd.value}' if \"No Adaptive Layer\" not in  adaptive_dd.value else None\n",
    "main_model_cfg=f'{MODELS_ROOT}/{model_dd.value}'\n",
    "\n",
    "print(\"Selected Adaptive Layer\", adaptive_layer_cfg)\n",
    "print(\"Selected Main Model\", main_model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545c63e27c2a449d8b5a042b4d2f9705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Evaluation', options=('select evaluation', 'demo.yaml', 'kfold.yaml', 'split.yaml'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................continuing...\n",
      "Selected Evaluation ./configs/evaluation/split.yaml\n"
     ]
    }
   ],
   "source": [
    "all_evaluations=sorted([f for f in os.listdir(EVAL_ROOT) if f.endswith(\".yaml\")])\n",
    "all_evaluations.insert(0,'select evaluation')\n",
    "eval_dd=ipywidgets.Dropdown(options=all_evaluations,description=\"Evaluation\")\n",
    "display(eval_dd)\n",
    "ju.wait_for_user(eval_dd)\n",
    "eval_cfg=f'{EVAL_ROOT}/{eval_dd.value}'\n",
    "print(\"Selected Evaluation\", eval_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset: !include ./configs/datasets/segpc.yaml\n",
      "evaluation: !include ./configs/evaluation/split.yaml\n",
      "run:\n",
      "    comet: False\n",
      "    save_dir: ./results/segpc/unet_3-2023-09-21T11-39-21\n",
      "\n",
      "model: !include ./configs/models/unet_3.yaml\n",
      "\n",
      "\n",
      "{\n",
      "  \"data_loader\": {\n",
      "    \"train\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"validation\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"test\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 4,\n",
      "      \"pin_memory\": false\n",
      "    }\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"optimizer\": {\n",
      "      \"name\": \"Adam\",\n",
      "      \"params\": {\n",
      "        \"lr\": 0.0001\n",
      "      }\n",
      "    },\n",
      "    \"criterion\": {\n",
      "      \"name\": \"DiceLoss\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "      \"factor\": 0.5,\n",
      "      \"patience\": 10\n",
      "    },\n",
      "    \"epochs\": 100\n",
      "  },\n",
      "  \"dataset\": {\n",
      "    \"title\": \"SegPC2021\",\n",
      "    \"class\": \"adaptive_mis.dataset.SegPC2021Dataset\",\n",
      "    \"params\": {\n",
      "      \"datadir\": \"datasets/SegPC2021\",\n",
      "      \"image_size\": 224,\n",
      "      \"crop_nucleus\": true,\n",
      "      \"crop_scale\": 2.5\n",
      "    }\n",
      "  },\n",
      "  \"evaluation\": {\n",
      "    \"class\": \"adaptive_mis.evaluation.Split\",\n",
      "    \"title\": \"Split\",\n",
      "    \"params\": {\n",
      "      \"seed\": 1,\n",
      "      \"val_size\": 0.2,\n",
      "      \"test_size\": 0.3\n",
      "    }\n",
      "  },\n",
      "  \"run\": {\n",
      "    \"comet\": false,\n",
      "    \"save_dir\": \"./results/segpc/unet_3-2023-09-21T11-39-21\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"class\": \"adaptive_mis.models.unet.UNet\",\n",
      "    \"load_weights\": false,\n",
      "    \"title\": \"UNet\",\n",
      "    \"params\": {\n",
      "      \"with_bn\": false,\n",
      "      \"first_kernel_size\": 3\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "def basename(path):\n",
    "    return os.path.basename(path).split('.')[0]\n",
    "\n",
    "\n",
    "if adaptive_layer_cfg:\n",
    "    model_cfg=f\"\"\"\n",
    "model: \n",
    "    class: \"adaptive_mis.models.adaptive.AdaptiveModel\"\n",
    "    title: \"AdaptCustom\"\n",
    "    load_weights: false\n",
    "    params:\n",
    "        adaptive_layer: !include {adaptive_layer_cfg}\n",
    "        main_model: !include {main_model_cfg}\n",
    "\"\"\"\n",
    "    model_title=f\"Adapt-{basename(adaptive_layer_cfg)}-{basename(main_model_cfg)}\"\n",
    "else:\n",
    "    model_cfg=f\"\"\"\n",
    "model: !include {main_model_cfg}\n",
    "\"\"\"\n",
    "    model_title=basename(main_model_cfg)\n",
    "    \n",
    "date = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "log = f'{basename(dataset_cfg)}/{model_title}-{date}'\n",
    "config=f\"\"\"\n",
    "dataset: !include {dataset_cfg}\n",
    "evaluation: !include {eval_cfg}\n",
    "run:\n",
    "    comet: False\n",
    "    save_dir: ./results/{log}\n",
    "{model_cfg}\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "print(config)\n",
    "\n",
    "\n",
    "cfg=load_config(f\"!include {CONFIG_ROOT}/common.yaml\")\n",
    "cfg.update(load_config(config))\n",
    "import json\n",
    "print(json.dumps(cfg, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cpu\n",
      "{\n",
      "  \"data_loader\": {\n",
      "    \"train\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"validation\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 8,\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"test\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 4,\n",
      "      \"pin_memory\": false\n",
      "    }\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"optimizer\": {\n",
      "      \"name\": \"Adam\",\n",
      "      \"params\": {\n",
      "        \"lr\": 0.0001\n",
      "      }\n",
      "    },\n",
      "    \"criterion\": {\n",
      "      \"name\": \"DiceLoss\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "      \"factor\": 0.5,\n",
      "      \"patience\": 10\n",
      "    },\n",
      "    \"epochs\": 100\n",
      "  },\n",
      "  \"dataset\": {\n",
      "    \"title\": \"SegPC2021\",\n",
      "    \"class\": \"adaptive_mis.dataset.SegPC2021Dataset\",\n",
      "    \"params\": {\n",
      "      \"datadir\": \"datasets/SegPC2021\",\n",
      "      \"image_size\": 224,\n",
      "      \"crop_nucleus\": true,\n",
      "      \"crop_scale\": 2.5\n",
      "    }\n",
      "  },\n",
      "  \"evaluation\": {\n",
      "    \"class\": \"adaptive_mis.evaluation.Split\",\n",
      "    \"title\": \"Split\",\n",
      "    \"params\": {\n",
      "      \"seed\": 1,\n",
      "      \"val_size\": 0.2,\n",
      "      \"test_size\": 0.3\n",
      "    }\n",
      "  },\n",
      "  \"run\": {\n",
      "    \"comet\": false,\n",
      "    \"save_dir\": \"./results/segpc/unet_3-2023-09-21T11-39-21\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"class\": \"adaptive_mis.models.unet.UNet\",\n",
      "    \"load_weights\": false,\n",
      "    \"title\": \"UNet\",\n",
      "    \"params\": {\n",
      "      \"with_bn\": false,\n",
      "      \"first_kernel_size\": 3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- \n",
      "\n",
      "~~~~~~~~~~~~~~~ Fold 0/0 ~~~~~~~~~~~~~~~~~\n",
      "Length of trainig_dataset:\t18\n",
      "Length of validation_dataset:\t5\n",
      "Length of test_dataset:\t\t10\n",
      "~~~~~~~~~~~~~~~ Fold 0/0 ~~~~~~~~~~~~~~~~~\n",
      "Number of parameters: 1947202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 224, 224]) torch.Size([16, 2, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 224, 224]) torch.Size([2, 2, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 224, 224]) torch.Size([5, 2, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train) ep:000, batch:0002 -> curr_ml:0.07628, mbatch_l:0.34296: 100%|██████████| 2/2 [00:30<00:00, 15.47s/it, trl=0.07628 vll=0.13692 best_vll=0.13692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 224, 224]) torch.Size([16, 2, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 224, 224]) torch.Size([2, 2, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\D\\Projects\\adaptive_mis\\notebooks\\2-Runner.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m adaptive_mis\u001b[39m.\u001b[39mreload()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39madaptive_mis\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/D/Projects/adaptive_mis/notebooks/2-Runner.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mexecute(cfg)\n",
      "File \u001b[1;32mc:\\D\\Projects\\adaptive_mis\\adaptive_mis\\pipeline.py:197\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m# optimizer=loader(config,\"optimzier\")\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mwith\u001b[39;00m experiment\u001b[39m.\u001b[39mtrain():\n\u001b[1;32m--> 197\u001b[0m     best_model, model, res \u001b[39m=\u001b[39m train(\n\u001b[0;32m    198\u001b[0m         model,\n\u001b[0;32m    199\u001b[0m         tr_dataloader,\n\u001b[0;32m    200\u001b[0m         vl_dataloader,\n\u001b[0;32m    201\u001b[0m         config,\n\u001b[0;32m    202\u001b[0m         optimizer,\n\u001b[0;32m    203\u001b[0m         scheduler,\n\u001b[0;32m    204\u001b[0m         save_dir\u001b[39m=\u001b[39;49msave_dir,\n\u001b[0;32m    205\u001b[0m         save_file_id\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    206\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[0;32m    207\u001b[0m         fold\u001b[39m=\u001b[39;49mfold\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    209\u001b[0m     log_model(experiment, best_model, model_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel_f\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m experiment\u001b[39m.\u001b[39mvalidate():\n",
      "File \u001b[1;32mc:\\D\\Projects\\adaptive_mis\\adaptive_mis\\pipeline.py:394\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, tr_dataloader, vl_dataloader, config, optimizer, scheduler, num_classes, fold, save_dir, save_file_id)\u001b[0m\n\u001b[0;32m    391\u001b[0m tr_cm \u001b[39m=\u001b[39m tr_metrics\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mtrain_ConfusionMatrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    393\u001b[0m \u001b[39mwith\u001b[39;00m experiment\u001b[39m.\u001b[39mvalidate():\n\u001b[1;32m--> 394\u001b[0m     vl_metrics, vl_loss \u001b[39m=\u001b[39m validate(model, criterion, vl_dataloader, valid_metrics, num_classes, config)\n\u001b[0;32m    395\u001b[0m     vl_metrics \u001b[39m=\u001b[39m serialize_metrics(vl_metrics\u001b[39m.\u001b[39mcompute())\n\u001b[0;32m    396\u001b[0m     vl_cm \u001b[39m=\u001b[39m vl_metrics\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvalid_ConfusionMatrix\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\D\\Projects\\adaptive_mis\\adaptive_mis\\pipeline.py:320\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(model, criterion, vl_dataloader, valid_metrics, num_classes, config)\u001b[0m\n\u001b[0;32m    318\u001b[0m tq \u001b[39m=\u001b[39m tqdm(vl_dataloader, disable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m tq\u001b[39m.\u001b[39mset_description(\u001b[39m'\u001b[39m\u001b[39mChecking Val...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 320\u001b[0m \u001b[39mfor\u001b[39;00m batch, batch_data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tq):\n\u001b[0;32m    321\u001b[0m     cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_data[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    323\u001b[0m     loss, preds_, msks_ \u001b[39m=\u001b[39m process_batch(batch_data, model, device, num_classes, config, criterion)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1170\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[39m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[39m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable:\n\u001b[1;32m-> 1170\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1171\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1172\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    885\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    817\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import adaptive_mis\n",
    "adaptive_mis.reload()\n",
    "from adaptive_mis import pipeline\n",
    "\n",
    "pipeline.execute(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
